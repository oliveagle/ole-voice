# 语音识别准确率提升技术路线图

> 本文档规划了 oleVoice 语音识别系统准确率提升的完整技术路径，从短期快速见效到长期系统性优化。

## 目录

- [当前状态](#当前状态)
- [短期方案（1-4周）](#短期方案1-4周)
- [中期方案（1-3个月）](#中期方案1-3个月)
- [长期方案（3-6个月）](#长期方案3-6个月)
- [实施建议](#实施建议)

---

## 当前状态

**基线模型**: mlx-community/Qwen3-ASR (0.6B/1.7B)
- 通用场景识别率良好
- 专业术语识别存在偏差
- 缺乏上下文纠错能力

**已实施**:
- [x] 热词词库（初步）
- [x] 多显示器支持
- [x] 基础架构优化

---

## 短期方案（1-4周）

### 1. 热词系统完善 ⭐ 最高优先级

**现状**: 已实现基础热词传递，但缺乏分类管理和动态权重

**改进方向**:

```
热词系统 2.0
├── 分类管理
│   ├── AI/ML 术语
│   ├── 编程语言/框架
│   ├── 人名/公司名
│   └── 用户个人词库
├── 权重机制
│   ├── 全局热词（通用术语）
│   ├── 场景热词（工作/生活切换）
│   └── 动态加权（根据使用频率）
└── 快速编辑
    ├── 菜单栏快捷添加
    ├── 语音自动提取候选
    └── 导入/导出功能
```

**准备工作**:
- 建立术语分类体系
- 收集更多领域词汇
- 设计快速添加UI

**预期收益**: 专业术语识别率 +15-25%

---

### 2. 后处理纠错 Pipeline

**方案**: 基于规则 + 轻量语言模型的文本纠错

```
原始识别结果
    ↓
[规则纠错层] - 拼音相似度、常见错误模式
    ↓
[轻量LM层] - 2-3层Transformer，本地运行
    ↓
[热词匹配] - 强制替换保证术语正确
    ↓
最终输出
```

**技术选型**:
| 方案 | 资源占用 | 延迟 | 准确率提升 |
|------|---------|------|-----------|
| 规则+词典 | 极低 | <10ms | +5% |
| 轻量BERT | 低 | 50-100ms | +10-15% |
| 云端大模型 | 无本地负担 | 500ms+ | +20%+ |

**推荐**: 先实现规则层，再逐步引入轻量LM

---

### 3. 识别结果置信度机制

**目标**: 低置信度结果自动提示或二次确认

**实现**:
- 提取模型输出的 token 概率
- 设定置信度阈值（如 <0.8 标记为可疑）
- 可疑词用特殊样式显示（如下划线）
- 用户可快速触发重识别

---

## 中期方案（1-3个月）

### 4. 领域微调 (Domain Fine-tuning)

**适用场景**: 特定领域深度使用（如程序员、医生、律师）

**技术方案**: LoRA/QLoRA 微调

```
预训练模型 (0.6B/1.7B)
    ↓
收集领域数据
    ├── 录屏 + 人工标注 (推荐)
    ├── 现有文稿合成语音
    └── 公开领域数据集
    ↓
LoRA微调 (rank=8-16)
    ├── 训练数据: 10-50小时
    ├── 训练时间: 数小时 (Apple Silicon)
    └── 模型大小: 原模型 + 10-50MB
    ↓
领域专用模型
```

**数据收集策略**:

| 方式 | 成本 | 质量 | 建议 |
|------|------|------|------|
| 人工录屏标注 | 高 | 最高 | 核心数据 |
| TTS合成 | 低 | 中 | 扩充数据 |
| 用户纠错反馈 | 极低 | 中高 | 持续积累 |

**准备工作**:
1. 开发数据收集工具（录屏+转录界面）
2. 建立标注规范和质量检查流程
3. 准备训练环境（mlx-examples/lora）

**预期收益**: 领域特定场景 +30-40% 准确率

---

### 5. 语言模型重打分 (LM Rescoring)

**原理**: 使用领域语言模型对 N-best 候选重新打分

```
语音识别 → Top-5 候选 → LM打分 → 选择最优
```

**技术实现**:
- N-gram LM: 轻量，适合本地
- 神经网络LM: 效果更好，资源消耗大
- 混合策略: N-gram 快速初筛 + 轻量NN精排

**准备工作**:
- 构建领域文本语料库
- 训练或下载预训练LM
- 集成到后处理pipeline

---

### 6. 数据飞轮建设

**核心**: 用户使用 → 纠错反馈 → 模型改进 → 体验提升

```
┌─────────────────────────────────────────┐
│              数据飞轮系统                │
├─────────────────────────────────────────┤
│                                         │
│   用户使用 → 识别错误 → 手动纠正        │
│      ↑                      ↓           │
│   体验提升 ← 模型更新 ← 数据积累        │
│                                         │
│   数据用途:                             │
│   1. 热词自动提取（高频纠正词）         │
│   2. 微调训练数据（高质量标注）         │
│   3. 错误模式分析（针对性优化）         │
│                                         │
└─────────────────────────────────────────┘
```

**实施要点**:
- 设计低摩擦的纠错反馈机制
- 用户隐私保护（本地处理优先）
- 数据质量自动筛选

---

## 长期方案（3-6个月）

### 7. 专用纠错模型

**方案**: 训练专门的 Seq2Seq 纠错模型

**输入**: 原始识别文本
**输出**: 纠错后的文本

**模型选型**:
- T5-small (60M参数): 本地可运行
- 基于错误类型设计数据增强策略

**训练数据**:
- 收集真实的错误-纠正对
- 人工构造常见错误模式
- 预计需要 1-10万条训练样本

---

### 8. 多模型融合策略

**方案**: 快慢模型结合

```
快速响应 (0.6B) ──┐
                  ├──→ 结果融合 ──→ 最终输出
精确识别 (1.7B) ──┘         ↑
                       置信度判断
```

**策略**:
- 0.6B 快速返回初步结果
- 低置信度片段用 1.7B 重识别
- 或两个模型结果投票融合

---

### 9. 自适应个性化学习

**目标**: 越用越懂你的专属模型

**技术路线**:
1. 本地缓存用户热词和习惯表达
2. 基于用户历史的动态语言模型
3. 轻量级在线学习（每次录音微调一点点）

**挑战**:
- 避免过拟合
- 控制计算资源消耗
- 隐私保护

---

## 实施建议

### 优先级矩阵

| 方案 | 投入成本 | 预期收益 | 推荐优先级 |
|------|---------|---------|-----------|
| 热词系统完善 | 低 | 中高 | ⭐⭐⭐⭐⭐ |
| 规则后处理 | 低 | 中 | ⭐⭐⭐⭐ |
| 数据飞轮 | 中 | 高 | ⭐⭐⭐⭐ |
| 领域微调 | 高 | 很高 | ⭐⭐⭐ |
| LM重打分 | 中 | 中高 | ⭐⭐⭐ |
| 纠错模型 | 很高 | 高 | ⭐⭐ |

### 推荐推进路线

**阶段一（即刻开始）**:
1. 完善热词系统（分类管理、快捷添加）
2. 实现规则后处理层
3. 启动数据收集（简单的纠错标记功能）

**阶段二（积累数据后）**:
4. 基于收集的数据进行领域微调
5. 实现LM重打分

**阶段三（数据充足后）**:
6. 训练专用纠错模型
7. 探索自适应学习

### 需要准备的基础设施

**数据收集**:
- [ ] 录屏标注工具
- [ ] 纠错反馈UI
- [ ] 数据存储和管理系统

**训练环境**:
- [ ] MLX训练脚本
- [ ] 数据预处理pipeline
- [ ] 模型评估框架

**部署**:
- [ ] 模型版本管理
- [ ] 增量更新机制
- [ ] A/B测试能力

---

## 附录

### 相关资源

- [mlx-examples/lora](https://github.com/ml-explore/mlx-examples/tree/main/lora) - LoRA微调示例
- [Whisper fine-tuning](https://github.com/openai/whisper/discussions/627) - 语音微调讨论
- [KenLM](https://github.com/kpu/kenlm) - N-gram语言模型工具

### 术语解释

| 术语 | 解释 |
|------|------|
| LoRA | 低秩适配，高效微调大模型的方法 |
| N-best | 语音识别输出的前N个候选结果 |
| Rescoring | 重新打分，用更精确的模型筛选候选 |
| TTS | 文本转语音，可用于合成训练数据 |

---

*文档版本: v1.0*
*更新日期: 2026-02-23*
*维护者: oleVoice Team*
