#!/usr/bin/env python3
"""
è¯­éŸ³è¾“å…¥å·¥å…· - èœå•æ ç‰ˆæœ¬ (ç¨³å®šå¯é )
ä½¿ç”¨ rumps åˆ›å»º macOS èœå•æ åº”ç”¨
"""

import rumps
import threading
import time
import wave
import tempfile
import os
from pathlib import Path

import yaml
import pyaudio
import pyperclip
from pynput import keyboard
from pynput.keyboard import Controller, Key

# å…¨å±€çŠ¶æ€
is_recording = False
recording_thread = None
audio_frames = []
config = {}
controller = Controller()
app = None


def load_config():
    """åŠ è½½é…ç½®"""
    try:
        config_path = Path(__file__).parent / "config.yaml"
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except:
        return {}


def record_audio():
    """å½•éŸ³"""
    global audio_frames

    try:
        audio = pyaudio.PyAudio()
        stream = audio.open(
            format=pyaudio.paInt16, channels=1, rate=16000,
            input=True, frames_per_buffer=1024
        )

        audio_frames = []
        start = time.time()

        while is_recording and time.time() - start < 60:
            try:
                data = stream.read(1024, exception_on_overflow=False)
                audio_frames.append(data)
            except:
                break

        stream.stop_stream()
        stream.close()
        audio.terminate()
    except Exception as e:
        print(f"å½•éŸ³é”™è¯¯: {e}")


def transcribe_audio(audio_path):
    """è½¬å½•"""
    try:
        from mlx_audio.stt.utils import load_model
        from mlx_audio.stt.generate import generate_transcription

        cache = Path.home() / ".cache/modelscope/hub/models/mlx-community/Qwen3-ASR-0.6B-8bit"
        model_path = str(cache) if cache.exists() else "mlx-community/Qwen3-ASR-0.6B-8bit"

        model = load_model(model_path)

        lang = config.get('model', {}).get('language', 'zh')
        lang_map = {'zh': 'Chinese', 'en': 'English', 'auto': 'Chinese'}

        result = generate_transcription(
            model=model,
            audio=audio_path,
            language=lang_map.get(lang, 'Chinese'),
            verbose=False
        )

        return result.text.strip() if hasattr(result, 'text') else str(result).strip()
    except Exception as e:
        print(f"è½¬å½•é”™è¯¯: {e}")
        return ""


def process_recording():
    """å¤„ç†å½•éŸ³"""
    try:
        # ä¿å­˜
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
            path = f.name

        wf = wave.open(path, 'wb')
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(16000)
        wf.writeframes(b''.join(audio_frames))
        wf.close()

        # è½¬å½•
        text = transcribe_audio(path)

        if text:
            # ç²˜è´´
            pyperclip.copy(text)
            time.sleep(0.1)
            with controller.pressed(Key.cmd):
                controller.press('v')
                controller.release('v')

            # æ˜¾ç¤ºç»“æœ
            rumps.notification("è¯­éŸ³è¾“å…¥", "è¯†åˆ«å®Œæˆ", text)
        else:
            rumps.notification("è¯­éŸ³è¾“å…¥", "æç¤º", "æœªèƒ½è¯†åˆ«è¯­éŸ³")

        # æ¸…ç†
        try:
            os.unlink(path)
        except:
            pass

    except Exception as e:
        rumps.notification("è¯­éŸ³è¾“å…¥", "é”™è¯¯", str(e))


def toggle_recording():
    """åˆ‡æ¢å½•éŸ³çŠ¶æ€"""
    global is_recording, recording_thread

    if not is_recording:
        # å¼€å§‹å½•éŸ³
        is_recording = True
        app.title = "ğŸ”´ å½•éŸ³ä¸­..."

        recording_thread = threading.Thread(target=record_audio, daemon=True)
        recording_thread.start()

        # æ˜¾ç¤º HUD æç¤º
        rumps.notification("è¯­éŸ³è¾“å…¥", "å¼€å§‹å½•éŸ³", "è¯·è¯´è¯ï¼Œå†æ¬¡æŒ‰å¿«æ·é”®åœæ­¢")
    else:
        # åœæ­¢å½•éŸ³
        is_recording = False
        if recording_thread:
            recording_thread.join(timeout=2)

        app.title = "ğŸ¤"

        # å¤„ç†å½•éŸ³
        threading.Thread(target=process_recording, daemon=True).start()


class VoiceApp(rumps.App):
    """è¯­éŸ³è¾“å…¥èœå•æ åº”ç”¨"""

    def __init__(self):
        global config
        config = load_config()

        super().__init__(
            name="è¯­éŸ³è¾“å…¥",
            title="ğŸ¤",
            icon=None,
            menu=[
                rumps.MenuItem("å¼€å§‹å½•éŸ³", callback=self.on_record),
                rumps.MenuItem("è®¾ç½®", callback=self.on_settings),
                None,  # åˆ†éš”çº¿
                rumps.MenuItem("é€€å‡º", callback=self.on_quit),
            ]
        )

        # å¯åŠ¨é”®ç›˜ç›‘å¬
        self.start_keyboard_listener()

    def start_keyboard_listener(self):
        """å¯åŠ¨é”®ç›˜ç›‘å¬"""
        key_map = {
            'cmd_l': keyboard.Key.cmd,
            'cmd_r': keyboard.Key.cmd_r,
            'cmd': keyboard.Key.cmd,
            'f8': keyboard.Key.f8,
        }

        target_key = key_map.get(config.get('hotkey', 'cmd_l'), keyboard.Key.cmd)
        last_trigger = [0]

        def on_press(k):
            if time.time() - last_trigger[0] < 0.5:
                return
            if k == target_key:
                last_trigger[0] = time.time()
                # åœ¨ä¸»çº¿ç¨‹æ‰§è¡Œ
                rumps.Timer(lambda _: toggle_recording(), 0.01).start()

        self.listener = keyboard.Listener(on_press=on_press)
        self.listener.start()

    def on_record(self, _):
        """èœå•ç‚¹å‡»ï¼šå½•éŸ³"""
        toggle_recording()

    def on_settings(self, _):
        """èœå•ç‚¹å‡»ï¼šè®¾ç½®"""
        rumps.alert("è®¾ç½®", "ç¼–è¾‘ config.yaml æ–‡ä»¶ä¿®æ”¹é…ç½®")

    def on_quit(self, _):
        """èœå•ç‚¹å‡»ï¼šé€€å‡º"""
        rumps.quit_application()


def main():
    global app
    app = VoiceApp()
    app.run()


if __name__ == '__main__':
    main()
